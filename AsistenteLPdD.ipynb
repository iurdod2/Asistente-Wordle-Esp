{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordle en EspaÃ±ol\n",
    "\n",
    "**Autor:** Pedro PÃ©rez Aguinaga\n",
    "Proyecto personal desarrollado en Python y desplegado como aplicaciÃ³n web usando **VoilÃ  + Binder**.\n",
    "\n",
    "Introduce palabras de 5 letras y descubre la palabra oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImportaciÃ³n de librerÃ­as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las bibliotecas necesarias para el proyecto: TensorFlow/Keras para el modelo de red neuronal, NumPy y pandas para manejo de datos, collections.Counter para conteo de letras, requests y json para descargar datasets de palabras en espaÃ±ol, re para expresiones regulares y widgets necesarios para VoilÃ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.662820Z",
     "iopub.status.busy": "2025-12-23T13:32:15.662395Z",
     "iopub.status.idle": "2025-12-23T13:32:15.668780Z",
     "shell.execute_reply": "2025-12-23T13:32:15.667554Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.662793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Proyecto Final - Inteligencia Artificial\n",
    "Asistente para Wordle en EspaÃ±ol (La palabra del dÃ­a)\n",
    "\"\"\"\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define una Ãºnica funciÃ³n para descargar, ya que probando a descargar desde fuentes externas como Github tenÃ­a errores, ademÃ¡s de que no he encontrado una API oficial de la RAE ni la API de donde la propia pÃ¡gina de 'La palabra del dÃ­a' saca sus palabras. TambiÃ©n incluye una funciÃ³n para filtrar palabras vÃ¡lidas para Wordle: exactamente 5 letras, sin tildes, sin caracteres especiales y con la letra Ã‘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.673919Z",
     "iopub.status.busy": "2025-12-23T13:32:15.673437Z",
     "iopub.status.idle": "2025-12-23T13:32:15.694704Z",
     "shell.execute_reply": "2025-12-23T13:32:15.693711Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.673886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def descargar_palabras_api():\n",
    "    \"\"\"\n",
    "    Descarga palabras de la API de palabras aleatorias espaÃ±olas\n",
    "    \"\"\"\n",
    "    # Esta es una fuente mÃ¡s limitada pero funcional\n",
    "    url = \"https://raw.githubusercontent.com/words/an-array-of-spanish-words/master/index.json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        palabras = json.loads(response.text)\n",
    "        print(f\"Descargadas {len(palabras)} palabras de API\")\n",
    "        return palabras\n",
    "    except:\n",
    "        raise Exception(\"No se pudieron descargar las palabras de ninguna fuente\")\n",
    "\n",
    "def filtrar_palabras_wordle(palabras):\n",
    "    \"\"\"\n",
    "    Filtra palabras para Wordle: 5 letras, sin tildes, sin caracteres especiales\n",
    "    \"\"\"\n",
    "    palabras_validas = []\n",
    "    \n",
    "    for palabra in palabras:\n",
    "        palabra = palabra.strip().upper()\n",
    "        \n",
    "        # Debe tener exactamente 5 letras\n",
    "        if len(palabra) != 5:\n",
    "            continue\n",
    "        \n",
    "        # Solo letras (sin nÃºmeros ni caracteres especiales)\n",
    "        if not palabra.isalpha():\n",
    "            continue\n",
    "        \n",
    "        # Sin tildes\n",
    "        if any(c in palabra for c in 'ÃÃ‰ÃÃ“ÃšÃœ'):\n",
    "            continue\n",
    "        \n",
    "        palabras_validas.append(palabra)\n",
    "    \n",
    "    # Eliminar duplicados\n",
    "    palabras_validas = list(set(palabras_validas))\n",
    "    \n",
    "    print(f\"Palabras vÃ¡lidas para Wordle: {len(palabras_validas)}\")\n",
    "    return sorted(palabras_validas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento y anÃ¡lisis de letras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene funciones para analizar la frecuencia de cada letra por posiciÃ³n en las palabras vÃ¡lidas y para crear un vector de caracterÃ­sticas por palabra que incluye frecuencia de letras, score por posiciÃ³n, diversidad de letras y score de frecuencia global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.696661Z",
     "iopub.status.busy": "2025-12-23T13:32:15.696291Z",
     "iopub.status.idle": "2025-12-23T13:32:15.715411Z",
     "shell.execute_reply": "2025-12-23T13:32:15.714561Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.696627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crear_estadisticas_letras(palabras):\n",
    "    \"\"\"\n",
    "    Analiza frecuencia de letras por posiciÃ³n\n",
    "    \"\"\"\n",
    "    estadisticas = {i: Counter() for i in range(5)}\n",
    "    frecuencia_global = Counter()\n",
    "    \n",
    "    for palabra in palabras:\n",
    "        for i, letra in enumerate(palabra):\n",
    "            estadisticas[i][letra] += 1\n",
    "            frecuencia_global[letra] += 1\n",
    "    \n",
    "    return estadisticas, frecuencia_global\n",
    "\n",
    "def crear_features_palabra(palabra, estadisticas, frecuencia_global):\n",
    "    \"\"\"\n",
    "    Crea vector de caracterÃ­sticas para una palabra\n",
    "    Features:\n",
    "    - 26 valores: frecuencia de cada letra del alfabeto\n",
    "    - 5 valores: score de cada posiciÃ³n\n",
    "    - 1 valor: diversidad de letras\n",
    "    - 1 valor: score total de frecuencia\n",
    "    \"\"\"\n",
    "    alfabeto = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    features = []\n",
    "    \n",
    "    # Frecuencia de cada letra en la palabra\n",
    "    for letra in alfabeto:\n",
    "        features.append(palabra.count(letra))\n",
    "    \n",
    "    # Score de posiciÃ³n para cada letra\n",
    "    for i, letra in enumerate(palabra):\n",
    "        score_pos = estadisticas[i].get(letra, 0) / len(estadisticas[i])\n",
    "        features.append(score_pos)\n",
    "    \n",
    "    # Diversidad de letras (penaliza letras repetidas)\n",
    "    diversidad = len(set(palabra)) / 5.0\n",
    "    features.append(diversidad)\n",
    "    \n",
    "    # Score de frecuencia global\n",
    "    score_freq = sum(frecuencia_global.get(letra, 0) for letra in palabra)\n",
    "    score_freq_norm = score_freq / sum(frecuencia_global.values())\n",
    "    features.append(score_freq_norm)\n",
    "    \n",
    "    return np.array(features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CreaciÃ³n del modelo de red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define la arquitectura de la red neuronal para clasificar palabras segÃºn su probabilidad de ser la respuesta correcta, utilizando capas densas y dropout para regularizaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.716742Z",
     "iopub.status.busy": "2025-12-23T13:32:15.716331Z",
     "iopub.status.idle": "2025-12-23T13:32:15.738099Z",
     "shell.execute_reply": "2025-12-23T13:32:15.736917Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.716717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crear_modelo():\n",
    "    \"\"\"\n",
    "    Red neuronal para scoring de palabras\n",
    "    \"\"\"\n",
    "    modelo = keras.Sequential([\n",
    "        layers.Input(shape=(33,)),  # 26 + 5 + 1 + 1\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Score de 0 a 1\n",
    "    ])\n",
    "    \n",
    "    modelo.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return modelo\n",
    "\n",
    "def generar_datos_entrenamiento(palabras, estadisticas, frecuencia_global):\n",
    "    \"\"\"\n",
    "    Genera datos de entrenamiento basados en caracterÃ­sticas lingÃ¼Ã­sticas\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Calculamos scores para todas las palabras\n",
    "    scores = []\n",
    "    for palabra in palabras:\n",
    "        # Score basado en frecuencia y diversidad\n",
    "        score_freq = sum(frecuencia_global.get(letra, 0) for letra in palabra)\n",
    "        diversidad = len(set(palabra)) / 5.0\n",
    "        score = (score_freq / sum(frecuencia_global.values())) * diversidad\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Normalizamos scores\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    \n",
    "    for palabra, score in zip(palabras, scores):\n",
    "        features = crear_features_palabra(palabra, estadisticas, frecuencia_global)\n",
    "        X.append(features)\n",
    "        # Normalizar score a [0, 1]\n",
    "        y.append((score - min_score) / (max_score - min_score))\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motor de sugerencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementa la clase principal del asistente que gestiona el estado del juego, filtra palabras candidatas segÃºn el feedback recibido y genera sugerencias basadas en probabilidad o en maximizar informaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.804848Z",
     "iopub.status.busy": "2025-12-23T13:32:15.803819Z",
     "iopub.status.idle": "2025-12-23T13:32:15.821212Z",
     "shell.execute_reply": "2025-12-23T13:32:15.820233Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.804803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WordleAssistant:\n",
    "    def __init__(self, palabras, modelo, estadisticas, frecuencia_global):\n",
    "        self.palabras = palabras\n",
    "        self.modelo = modelo\n",
    "        self.estadisticas = estadisticas\n",
    "        self.frecuencia_global = frecuencia_global\n",
    "        self.letras_verdes = {}  # {posicion: letra}\n",
    "        self.letras_amarillas = set()  # letras que estÃ¡n pero en otra posiciÃ³n\n",
    "        self.letras_amarillas_pos = {}  # {letra: [posiciones_donde_NO_estÃ¡]}\n",
    "        self.letras_negras = set()\n",
    "    \n",
    "    def actualizar_feedback(self, palabra, feedback):\n",
    "        \"\"\"\n",
    "        Actualiza el estado con el feedback del intento\n",
    "        palabra: str, la palabra intentada\n",
    "        feedback: str, 5 caracteres con 'V'(verde), 'A'(amarillo), 'N'(negro)\n",
    "        Ejemplo: \"VNANV\" significa verde-negro-amarillo-negro-verde\n",
    "        \"\"\"\n",
    "        palabra = palabra.upper()\n",
    "        feedback = feedback.upper()\n",
    "        \n",
    "        for i, (letra, color) in enumerate(zip(palabra, feedback)):\n",
    "            if color == 'V':\n",
    "                self.letras_verdes[i] = letra\n",
    "                self.letras_amarillas.discard(letra)  # Ya no es amarilla\n",
    "            elif color == 'A':\n",
    "                self.letras_amarillas.add(letra)\n",
    "                if letra not in self.letras_amarillas_pos:\n",
    "                    self.letras_amarillas_pos[letra] = []\n",
    "                self.letras_amarillas_pos[letra].append(i)\n",
    "            elif color == 'N':\n",
    "                # Solo marcar como negra si no estÃ¡ verde o amarilla\n",
    "                if letra not in self.letras_verdes.values() and letra not in self.letras_amarillas:\n",
    "                    self.letras_negras.add(letra)\n",
    "    \n",
    "    def filtrar_candidatas(self):\n",
    "        \"\"\"\n",
    "        Filtra palabras segÃºn restricciones actuales\n",
    "        \"\"\"\n",
    "        candidatas = []\n",
    "        \n",
    "        for palabra in self.palabras:\n",
    "            valida = True\n",
    "            \n",
    "            # Verificar letras verdes (deben estar en su posiciÃ³n)\n",
    "            for pos, letra in self.letras_verdes.items():\n",
    "                if palabra[pos] != letra:\n",
    "                    valida = False\n",
    "                    break\n",
    "            \n",
    "            if not valida:\n",
    "                continue\n",
    "            \n",
    "            # Verificar letras amarillas (deben estar pero no en ciertas posiciones)\n",
    "            for letra in self.letras_amarillas:\n",
    "                if letra not in palabra:\n",
    "                    valida = False\n",
    "                    break\n",
    "                # Verificar que no estÃ© en posiciones descartadas\n",
    "                if letra in self.letras_amarillas_pos:\n",
    "                    for pos_no in self.letras_amarillas_pos[letra]:\n",
    "                        if palabra[pos_no] == letra:\n",
    "                            valida = False\n",
    "                            break\n",
    "            \n",
    "            if not valida:\n",
    "                continue\n",
    "            \n",
    "            # Verificar letras negras (no deben estar)\n",
    "            for letra in self.letras_negras:\n",
    "                if letra in palabra:\n",
    "                    valida = False\n",
    "                    break\n",
    "            \n",
    "            if valida:\n",
    "                candidatas.append(palabra)\n",
    "        \n",
    "        return candidatas\n",
    "    \n",
    "    def sugerir_palabra_probable(self, top_n=5):\n",
    "        \"\"\"\n",
    "        Sugiere las palabras mÃ¡s probables de ser la respuesta\n",
    "        \"\"\"\n",
    "        candidatas = self.filtrar_candidatas()\n",
    "        \n",
    "        if not candidatas:\n",
    "            return []\n",
    "        \n",
    "        # Crear features y predecir\n",
    "        features = np.array([\n",
    "            crear_features_palabra(p, self.estadisticas, self.frecuencia_global)\n",
    "            for p in candidatas\n",
    "        ])\n",
    "        \n",
    "        scores = self.modelo.predict(features, verbose=0).flatten()\n",
    "        \n",
    "        # Ordenar por score\n",
    "        indices_ordenados = np.argsort(scores)[::-1]\n",
    "        \n",
    "        return [(candidatas[i], float(scores[i])) for i in indices_ordenados[:top_n]]\n",
    "    \n",
    "    def sugerir_palabra_exploradora(self, top_n=5):\n",
    "        \"\"\"\n",
    "        Sugiere palabras que maximicen la informaciÃ³n (mÃ¡s letras diferentes)\n",
    "        \"\"\"\n",
    "        candidatas = self.filtrar_candidatas()\n",
    "        \n",
    "        if not candidatas:\n",
    "            return []\n",
    "        \n",
    "        # Calcular score de exploraciÃ³n\n",
    "        scores_exploracion = []\n",
    "        for palabra in candidatas:\n",
    "            # Contar letras Ãºnicas no descubiertas\n",
    "            letras_conocidas = set(self.letras_verdes.values()) | self.letras_amarillas | self.letras_negras\n",
    "            letras_nuevas = set(palabra) - letras_conocidas\n",
    "            # Score: cantidad de letras nuevas * frecuencia promedio\n",
    "            score = len(letras_nuevas) * sum(self.frecuencia_global.get(l, 0) for l in letras_nuevas)\n",
    "            scores_exploracion.append(score)\n",
    "        \n",
    "        # Ordenar por score de exploraciÃ³n\n",
    "        indices_ordenados = np.argsort(scores_exploracion)[::-1]\n",
    "        \n",
    "        return [(candidatas[i], float(scores_exploracion[i])) for i in indices_ordenados[:top_n]]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reinicia el asistente para una nueva partida\"\"\"\n",
    "        self.letras_verdes = {}\n",
    "        self.letras_amarillas = set()\n",
    "        self.letras_amarillas_pos = {}\n",
    "        self.letras_negras = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proporciona funciones para procesar entradas del usuario en formato PALABRA/COLORES y un modo interactivo que permite jugar mÃºltiples partidas con el asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.822863Z",
     "iopub.status.busy": "2025-12-23T13:32:15.822552Z",
     "iopub.status.idle": "2025-12-23T13:32:15.848658Z",
     "shell.execute_reply": "2025-12-23T13:32:15.847285Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.822840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crear_interfaz(asistente):\n",
    "    # Estilos CSS\n",
    "    display(HTML(\"\"\"\n",
    "    <style>\n",
    "        .wordle-title {\n",
    "            text-align: center;\n",
    "            color: #2c3e50;\n",
    "            font-size: 32px;\n",
    "            font-weight: bold;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .wordle-subtitle {\n",
    "            text-align: center;\n",
    "            color: #7f8c8d;\n",
    "            font-size: 16px;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "        .resultado-box {\n",
    "            background: #E09116;\n",
    "            border-left: 4px solid #4CAF50;\n",
    "            padding: 15px;\n",
    "            margin: 10px 0;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        .candidatas-count {\n",
    "            font-size: 20px;\n",
    "        }\n",
    "        .palabra-sugerida {\n",
    "            background: #2c3e50;\n",
    "            padding: 10px;\n",
    "            margin: 5px 0;\n",
    "            border-radius: 5px;\n",
    "            font-family: monospace;\n",
    "            font-size: 16px;\n",
    "        }\n",
    "    </style>\n",
    "    <div class=\"wordle-title\">Asistente Wordle EspaÃ±ol</div>\n",
    "    <div class=\"wordle-subtitle\">Proyecto de Inteligencia Artificial - La Palabra del DÃ­a</div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Widgets\n",
    "    palabra_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Ej: CANTO',\n",
    "        description='Palabra:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    colores_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Ej: VAANN',\n",
    "        description='Colores:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    enviar_btn = widgets.Button(\n",
    "        description='Analizar',\n",
    "        button_style='primary',\n",
    "        #layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    \n",
    "    reset_btn = widgets.Button(\n",
    "        description='Nueva Partida',\n",
    "        button_style='warning',\n",
    "        #layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Instrucciones\n",
    "    instrucciones = widgets.HTML(\"\"\"\n",
    "    <div style='background: #2c3e50; padding: 15px; border-radius: 5px; margin: 10px 0;'>\n",
    "        <b>ğŸ“– Instrucciones:</b><br>\n",
    "        1. Introduce la palabra que probaste en Wordle<br>\n",
    "        2. Introduce los colores: <b>V</b>=Verde, <b>A</b>=Amarillo, <b>N</b>=Negro<br>\n",
    "        3. Haz clic en \"Analizar\" para obtener sugerencias<br><br>\n",
    "        <i>Ejemplo: Si probaste CANTO y obtuviste ğŸŸ©â¬›ğŸŸ¨â¬›â¬›â¬›, escribe VAANN</i>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    def procesar_intento(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            palabra = palabra_input.value.strip().upper()\n",
    "            colores = colores_input.value.strip().upper()\n",
    "            \n",
    "            # Validaciones\n",
    "            if len(palabra) != 5:\n",
    "                print(\"âŒ Error: La palabra debe tener 5 letras\")\n",
    "                return\n",
    "            if len(colores) != 5:\n",
    "                print(\"âŒ Error: Debes proporcionar 5 colores\")\n",
    "                return\n",
    "            if not all(c in 'VAN' for c in colores):\n",
    "                print(\"âŒ Error: Solo usa V, A o N para los colores\")\n",
    "                return\n",
    "            \n",
    "            # Actualizar y obtener sugerencias\n",
    "            asistente.actualizar_feedback(palabra, colores)\n",
    "            candidatas = asistente.filtrar_candidatas()\n",
    "            \n",
    "            display(HTML(f\"\"\"\n",
    "            <div class=\"resultado-box\">\n",
    "                <h3>Intento procesado: {palabra} â†’ {colores}</h3>\n",
    "                <p class=\"candidatas-count\">Candidatas restantes: {len(candidatas)}</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            \n",
    "            if len(candidatas) == 0:\n",
    "                print(\"âš ï¸ No quedan candidatas. Verifica los colores ingresados.\")\n",
    "                return\n",
    "            \n",
    "            # Top palabras probables\n",
    "            print(\"\\nğŸ† TOP 5 PALABRAS MÃS PROBABLES:\")\n",
    "            probables = asistente.sugerir_palabra_probable(top_n=5)\n",
    "            for i, (pal, score) in enumerate(probables, 1):\n",
    "                display(HTML(f'<div class=\"palabra-sugerida\">{i}. <b>{pal}</b> (confianza: {score:.4f})</div>'))\n",
    "            \n",
    "            # Palabras exploradoras\n",
    "            print(\"\\nğŸ” TOP 5 PALABRAS QUE APORTAN MÃS INFORMACIÃ“N:\")\n",
    "            exploradoras = asistente.sugerir_palabra_exploradora(top_n=5)\n",
    "            for i, (pal, score) in enumerate(exploradoras, 1):\n",
    "                display(HTML(f'<div class=\"palabra-sugerida\">{i}. <b>{pal}</b> (info: {score:.1f})</div>'))\n",
    "            \n",
    "            # Estado actual\n",
    "            if asistente.letras_verdes or asistente.letras_amarillas or asistente.letras_negras:\n",
    "                print(\"\\nğŸ“Œ ESTADO ACTUAL:\")\n",
    "                if asistente.letras_verdes:\n",
    "                    print(f\"   ğŸŸ© Verdes: {asistente.letras_verdes}\")\n",
    "                if asistente.letras_amarillas:\n",
    "                    print(f\"   ğŸŸ¨ Amarillas: {asistente.letras_amarillas}\")\n",
    "                if asistente.letras_negras:\n",
    "                    print(f\"   â¬› Negras: {asistente.letras_negras}\")\n",
    "            \n",
    "            # Limpiar inputs\n",
    "            palabra_input.value = ''\n",
    "            colores_input.value = ''\n",
    "    \n",
    "    def resetear(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            asistente.reset()\n",
    "            palabra_input.value = ''\n",
    "            colores_input.value = ''\n",
    "            print(\"ğŸ”„ Asistente reiniciado. Â¡Nueva partida iniciada!\")\n",
    "    \n",
    "    enviar_btn.on_click(procesar_intento)\n",
    "    reset_btn.on_click(resetear)\n",
    "    \n",
    "    # Layout\n",
    "    input_box = widgets.VBox(\n",
    "        [\n",
    "            widgets.HBox([palabra_input, colores_input]),\n",
    "            enviar_btn,\n",
    "            reset_btn\n",
    "        ],\n",
    "        layout=widgets.Layout(\n",
    "            width='90%',\n",
    "            gap='15px'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    contenedor = widgets.HBox(\n",
    "        [input_box],\n",
    "        layout=widgets.Layout(justify_content='center')\n",
    "    )\n",
    "\n",
    "    \n",
    "    display(instrucciones)\n",
    "    display(input_box)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EjecuciÃ³n principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene la funciÃ³n main() que orquesta todo el flujo del programa: descarga de palabras, entrenamiento del modelo, inicializaciÃ³n del asistente y gestiÃ³n del modo interactivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.849942Z",
     "iopub.status.busy": "2025-12-23T13:32:15.849677Z",
     "iopub.status.idle": "2025-12-23T13:32:36.146746Z",
     "shell.execute_reply": "2025-12-23T13:32:36.145727Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.849920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando asistente...\n",
      "Descargadas 636598 palabras de API\n",
      "Palabras vÃ¡lidas para Wordle: 10836\n",
      " 10836 palabras cargadas\n",
      "\n",
      "2. Analizando frecuencias de letras...\n",
      " EstadÃ­sticas calculadas\n",
      "   Letras mÃ¡s comunes: [('A', 8814), ('E', 5378), ('O', 5337), ('S', 3844), ('R', 3666)]\n",
      "\n",
      "3. Generando datos de entrenamiento...\n",
      "\n",
      "4. Entrenando modelo de red neuronal...\n",
      "Entrenando modelo...\n",
      "Epoch 1/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 3.4866e-04 - loss: 1.3486 - val_accuracy: 0.0000e+00 - val_loss: 0.6891\n",
      "Epoch 2/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 3.2881e-04 - loss: 0.6981 - val_accuracy: 4.6125e-04 - val_loss: 0.6866\n",
      "Epoch 3/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 9.9231e-04 - loss: 0.6826 - val_accuracy: 4.6125e-04 - val_loss: 0.6854\n",
      "Epoch 4/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0010 - loss: 0.6802 - val_accuracy: 4.6125e-04 - val_loss: 0.6821\n",
      "Epoch 5/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 2.3524e-04 - loss: 0.6776 - val_accuracy: 9.2251e-04 - val_loss: 0.6836\n",
      "Epoch 6/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 3.7638e-04 - loss: 0.6762 - val_accuracy: 9.2251e-04 - val_loss: 0.6826\n",
      "Epoch 7/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 4.4138e-04 - loss: 0.6736 - val_accuracy: 9.2251e-04 - val_loss: 0.6813\n",
      "Epoch 8/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 4.6221e-04 - loss: 0.6732 - val_accuracy: 9.2251e-04 - val_loss: 0.6796\n",
      "Epoch 9/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 9.6728e-04 - loss: 0.6723 - val_accuracy: 9.2251e-04 - val_loss: 0.6784\n",
      "Epoch 10/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 4.2076e-04 - loss: 0.6690 - val_accuracy: 9.2251e-04 - val_loss: 0.6724\n",
      "Epoch 11/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0015 - loss: 0.6654 - val_accuracy: 9.2251e-04 - val_loss: 0.6748\n",
      "Epoch 12/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 5.8217e-04 - loss: 0.6634 - val_accuracy: 9.2251e-04 - val_loss: 0.6676\n",
      "Epoch 13/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 4.9141e-04 - loss: 0.6617 - val_accuracy: 9.2251e-04 - val_loss: 0.6644\n",
      "Epoch 14/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 5.7271e-04 - loss: 0.6601 - val_accuracy: 9.2251e-04 - val_loss: 0.6632\n",
      "Epoch 15/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 5.0932e-04 - loss: 0.6563 - val_accuracy: 9.2251e-04 - val_loss: 0.6618\n",
      "Epoch 16/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 7.3159e-04 - loss: 0.6550 - val_accuracy: 9.2251e-04 - val_loss: 0.6617\n",
      "Epoch 17/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0014 - loss: 0.6536 - val_accuracy: 9.2251e-04 - val_loss: 0.6603\n",
      "Epoch 18/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 4.9491e-04 - loss: 0.6523 - val_accuracy: 9.2251e-04 - val_loss: 0.6657\n",
      "Epoch 19/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 7.6654e-04 - loss: 0.6520 - val_accuracy: 9.2251e-04 - val_loss: 0.6584\n",
      "Epoch 20/20\n",
      "\u001b[1m271/271\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 7.0989e-04 - loss: 0.6511 - val_accuracy: 9.2251e-04 - val_loss: 0.6577\n",
      "Modelo entrenado\n",
      "\n",
      "5. Inicializando asistente...\n",
      "\n",
      "======================================================================\n",
      "ASISTENTE LISTO\n",
      "======================================================================\n",
      "\n",
      "6. Guardando modelo y datos...\n",
      "   Modelo guardado como 'wordle_assistant_model.keras'\n",
      "   Palabras guardadas en 'palabras_wordle.txt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wordle-title {\n",
       "            text-align: center;\n",
       "            color: #2c3e50;\n",
       "            font-size: 32px;\n",
       "            font-weight: bold;\n",
       "            margin: 20px 0;\n",
       "        }\n",
       "        .wordle-subtitle {\n",
       "            text-align: center;\n",
       "            color: #7f8c8d;\n",
       "            font-size: 16px;\n",
       "            margin-bottom: 30px;\n",
       "        }\n",
       "        .resultado-box {\n",
       "            background: #E09116;\n",
       "            border-left: 4px solid #4CAF50;\n",
       "            padding: 15px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .candidatas-count {\n",
       "            font-size: 20px;\n",
       "        }\n",
       "        .palabra-sugerida {\n",
       "            background: #2c3e50;\n",
       "            padding: 10px;\n",
       "            margin: 5px 0;\n",
       "            border-radius: 5px;\n",
       "            font-family: monospace;\n",
       "            font-size: 16px;\n",
       "        }\n",
       "    </style>\n",
       "    <div class=\"wordle-title\">Asistente Wordle EspaÃ±ol</div>\n",
       "    <div class=\"wordle-subtitle\">Proyecto de Inteligencia Artificial - La Palabra del DÃ­a</div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179bc0fe170d4faab6698e0d95ba36d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n    <div style=\\'background: #2c3e50; padding: 15px; border-radius: 5px; margin: 10px 0;\\'>\\n   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a489b6007584eb29166936d2bc34ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Palabra:', layout=Layout(width='300px'), placeholderâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abede00650a243d9be1a039f2b0fde32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # 1. Descargar y preparar palabras\n",
    "    print(\"Inicializando asistente...\")\n",
    "    palabras_raw = descargar_palabras_api()\n",
    "    palabras = filtrar_palabras_wordle(palabras_raw)\n",
    "    print(f\" {len(palabras)} palabras cargadas\")\n",
    "    \n",
    "    # 2. Crear estadÃ­sticas\n",
    "    print(\"\\n2. Analizando frecuencias de letras...\")\n",
    "    estadisticas, frecuencia_global = crear_estadisticas_letras(palabras)\n",
    "    print(\" EstadÃ­sticas calculadas\")\n",
    "    print(f\"   Letras mÃ¡s comunes: {frecuencia_global.most_common(5)}\")\n",
    "    \n",
    "    # 3. Preparar datos de entrenamiento\n",
    "    print(\"\\n3. Generando datos de entrenamiento...\")\n",
    "    X, y = generar_datos_entrenamiento(palabras, estadisticas, frecuencia_global)\n",
    "    \n",
    "    # 4. Entrenar modelo\n",
    "    print(\"\\n4. Entrenando modelo de red neuronal...\")\n",
    "    modelo = crear_modelo()\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    print(\"Entrenando modelo...\")\n",
    "    modelo.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "               epochs=20, batch_size=32, verbose=1)\n",
    "    print(\"Modelo entrenado\")\n",
    "    \n",
    "    # 5. Crear asistente\n",
    "    print(\"\\n5. Inicializando asistente...\")\n",
    "    asistente = WordleAssistant(palabras, modelo, estadisticas, frecuencia_global)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ASISTENTE LISTO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Guardar modelo y datos\n",
    "    print(\"\\n6. Guardando modelo y datos...\")\n",
    "    modelo.save('wordle_assistant_model.keras')\n",
    "    print(\"   Modelo guardado como 'wordle_assistant_model.keras'\")\n",
    "    \n",
    "    with open('palabras_wordle.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(palabras))\n",
    "    print(\"   Palabras guardadas en 'palabras_wordle.txt'\")\n",
    "    \n",
    "    return asistente, modelo, palabras, estadisticas, frecuencia_global\n",
    "\n",
    "# Ejecutar\n",
    "# Inicializar el asistente\n",
    "asistente, modelo, palabras, estadisticas, frecuencia_global = main()\n",
    "\n",
    "# Crear interfaz interactiva\n",
    "crear_interfaz(asistente)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
