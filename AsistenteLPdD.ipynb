{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordle en Espa√±ol\n",
    "\n",
    "**Autor:** Pedro P√©rez Aguinaga\n",
    "\n",
    "Introduce palabras de 5 letras y descubre la palabra oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las bibliotecas necesarias para el proyecto: TensorFlow/Keras para el modelo de red neuronal, NumPy y pandas para manejo de datos, collections.Counter para conteo de letras, requests y json para descargar datasets de palabras en espa√±ol, re para expresiones regulares y widgets necesarios para Voil√†."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.662820Z",
     "iopub.status.busy": "2025-12-23T13:32:15.662395Z",
     "iopub.status.idle": "2025-12-23T13:32:15.668780Z",
     "shell.execute_reply": "2025-12-23T13:32:15.667554Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.662793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Proyecto Final - Inteligencia Artificial\n",
    "Asistente para Wordle en Espa√±ol (La palabra del d√≠a)\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define una √∫nica funci√≥n para descargar, ya que probando a descargar desde fuentes externas como Github ten√≠a errores, adem√°s de que no he encontrado una API oficial de la RAE ni la API de donde la propia p√°gina de 'La palabra del d√≠a' saca sus palabras. Tambi√©n incluye una funci√≥n para filtrar palabras v√°lidas para Wordle: exactamente 5 letras, sin tildes, sin caracteres especiales y con la letra √ë."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.673919Z",
     "iopub.status.busy": "2025-12-23T13:32:15.673437Z",
     "iopub.status.idle": "2025-12-23T13:32:15.694704Z",
     "shell.execute_reply": "2025-12-23T13:32:15.693711Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.673886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def descargar_palabras_api():\n",
    "    \"\"\"\n",
    "    Descarga palabras de la API de palabras aleatorias espa√±olas\n",
    "    \"\"\"\n",
    "    # Esta es una fuente m√°s limitada pero funcional\n",
    "    url = \"https://raw.githubusercontent.com/words/an-array-of-spanish-words/master/index.json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        palabras = json.loads(response.text)\n",
    "        print(f\"Descargadas {len(palabras)} palabras de API\")\n",
    "        return palabras\n",
    "    except:\n",
    "        raise Exception(\"No se pudieron descargar las palabras de ninguna fuente\")\n",
    "\n",
    "def filtrar_palabras_wordle(palabras):\n",
    "    \"\"\"\n",
    "    Filtra palabras para Wordle: 5 letras, sin tildes, sin caracteres especiales\n",
    "    \"\"\"\n",
    "    palabras_validas = []\n",
    "    \n",
    "    for palabra in palabras:\n",
    "        palabra = palabra.strip().upper()\n",
    "        \n",
    "        # Debe tener exactamente 5 letras\n",
    "        if len(palabra) != 5:\n",
    "            continue\n",
    "        \n",
    "        # Solo letras (sin n√∫meros ni caracteres especiales)\n",
    "        if not palabra.isalpha():\n",
    "            continue\n",
    "        \n",
    "        # Sin tildes\n",
    "        if any(c in palabra for c in '√Å√â√ç√ì√ö√ú'):\n",
    "            continue\n",
    "        \n",
    "        palabras_validas.append(palabra)\n",
    "    \n",
    "    # Eliminar duplicados\n",
    "    palabras_validas = list(set(palabras_validas))\n",
    "    \n",
    "    print(f\"Palabras v√°lidas para Wordle: {len(palabras_validas)}\")\n",
    "    return sorted(palabras_validas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento y an√°lisis de letras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene funciones para analizar la frecuencia de cada letra por posici√≥n en las palabras v√°lidas y para crear un vector de caracter√≠sticas por palabra que incluye frecuencia de letras, score por posici√≥n, diversidad de letras y score de frecuencia global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.696661Z",
     "iopub.status.busy": "2025-12-23T13:32:15.696291Z",
     "iopub.status.idle": "2025-12-23T13:32:15.715411Z",
     "shell.execute_reply": "2025-12-23T13:32:15.714561Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.696627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crear_estadisticas_letras(palabras):\n",
    "    \"\"\"\n",
    "    Analiza frecuencia de letras por posici√≥n\n",
    "    \"\"\"\n",
    "    estadisticas = {i: Counter() for i in range(5)}\n",
    "    frecuencia_global = Counter()\n",
    "    \n",
    "    for palabra in palabras:\n",
    "        for i, letra in enumerate(palabra):\n",
    "            estadisticas[i][letra] += 1\n",
    "            frecuencia_global[letra] += 1\n",
    "    \n",
    "    return estadisticas, frecuencia_global\n",
    "\n",
    "def crear_features_palabra(palabra, estadisticas, frecuencia_global):\n",
    "    \"\"\"\n",
    "    Crea vector de caracter√≠sticas para una palabra\n",
    "    Features:\n",
    "    - 26 valores: frecuencia de cada letra del alfabeto\n",
    "    - 5 valores: score de cada posici√≥n\n",
    "    - 1 valor: diversidad de letras\n",
    "    - 1 valor: score total de frecuencia\n",
    "    \"\"\"\n",
    "    alfabeto = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    features = []\n",
    "    \n",
    "    # Frecuencia de cada letra en la palabra\n",
    "    for letra in alfabeto:\n",
    "        features.append(palabra.count(letra))\n",
    "    \n",
    "    # Score de posici√≥n para cada letra\n",
    "    for i, letra in enumerate(palabra):\n",
    "        score_pos = estadisticas[i].get(letra, 0) / len(estadisticas[i])\n",
    "        features.append(score_pos)\n",
    "    \n",
    "    # Diversidad de letras (penaliza letras repetidas)\n",
    "    diversidad = len(set(palabra)) / 5.0\n",
    "    features.append(diversidad)\n",
    "    \n",
    "    # Score de frecuencia global\n",
    "    score_freq = sum(frecuencia_global.get(letra, 0) for letra in palabra)\n",
    "    score_freq_norm = score_freq / sum(frecuencia_global.values())\n",
    "    features.append(score_freq_norm)\n",
    "    \n",
    "    return np.array(features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci√≥n del modelo de red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define la arquitectura de la red neuronal para clasificar palabras seg√∫n su probabilidad de ser la respuesta correcta, utilizando capas densas y dropout para regularizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.716742Z",
     "iopub.status.busy": "2025-12-23T13:32:15.716331Z",
     "iopub.status.idle": "2025-12-23T13:32:15.738099Z",
     "shell.execute_reply": "2025-12-23T13:32:15.736917Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.716717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crear_modelo():\n",
    "    \"\"\"\n",
    "    Red neuronal para scoring de palabras\n",
    "    \"\"\"\n",
    "    modelo = keras.Sequential([\n",
    "        layers.Input(shape=(33,)),  # 26 + 5 + 1 + 1\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Score de 0 a 1\n",
    "    ])\n",
    "    \n",
    "    modelo.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return modelo\n",
    "\n",
    "def generar_datos_entrenamiento(palabras, estadisticas, frecuencia_global):\n",
    "    \"\"\"\n",
    "    Genera datos de entrenamiento basados en caracter√≠sticas ling√º√≠sticas\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Calculamos scores para todas las palabras\n",
    "    scores = []\n",
    "    for palabra in palabras:\n",
    "        # Score basado en frecuencia y diversidad\n",
    "        score_freq = sum(frecuencia_global.get(letra, 0) for letra in palabra)\n",
    "        diversidad = len(set(palabra)) / 5.0\n",
    "        score = (score_freq / sum(frecuencia_global.values())) * diversidad\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Normalizamos scores\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    \n",
    "    for palabra, score in zip(palabras, scores):\n",
    "        features = crear_features_palabra(palabra, estadisticas, frecuencia_global)\n",
    "        X.append(features)\n",
    "        # Normalizar score a [0, 1]\n",
    "        y.append((score - min_score) / (max_score - min_score))\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motor de sugerencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementa la clase principal del asistente que gestiona el estado del juego, filtra palabras candidatas seg√∫n el feedback recibido y genera sugerencias basadas en probabilidad o en maximizar informaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.804848Z",
     "iopub.status.busy": "2025-12-23T13:32:15.803819Z",
     "iopub.status.idle": "2025-12-23T13:32:15.821212Z",
     "shell.execute_reply": "2025-12-23T13:32:15.820233Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.804803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WordleAssistant:\n",
    "    def __init__(self, palabras, modelo, estadisticas, frecuencia_global):\n",
    "        self.palabras = palabras\n",
    "        self.modelo = modelo\n",
    "        self.estadisticas = estadisticas\n",
    "        self.frecuencia_global = frecuencia_global\n",
    "        self.letras_verdes = {}  # {posicion: letra}\n",
    "        self.letras_amarillas = set()  # letras que est√°n pero en otra posici√≥n\n",
    "        self.letras_amarillas_pos = {}  # {letra: [posiciones_donde_NO_est√°]}\n",
    "        self.letras_negras = set()\n",
    "    \n",
    "    def actualizar_feedback(self, palabra, feedback):\n",
    "        \"\"\"\n",
    "        Actualiza el estado con el feedback del intento\n",
    "        palabra: str, la palabra intentada\n",
    "        feedback: str, 5 caracteres con 'V'(verde), 'A'(amarillo), 'N'(negro)\n",
    "        Ejemplo: \"VNANV\" significa verde-negro-amarillo-negro-verde\n",
    "        \"\"\"\n",
    "        palabra = palabra.upper()\n",
    "        feedback = feedback.upper()\n",
    "        \n",
    "        for i, (letra, color) in enumerate(zip(palabra, feedback)):\n",
    "            if color == 'V':\n",
    "                self.letras_verdes[i] = letra\n",
    "                self.letras_amarillas.discard(letra)  # Ya no es amarilla\n",
    "            elif color == 'A':\n",
    "                self.letras_amarillas.add(letra)\n",
    "                if letra not in self.letras_amarillas_pos:\n",
    "                    self.letras_amarillas_pos[letra] = []\n",
    "                self.letras_amarillas_pos[letra].append(i)\n",
    "            elif color == 'N':\n",
    "                # Solo marcar como negra si no est√° verde o amarilla\n",
    "                if letra not in self.letras_verdes.values() and letra not in self.letras_amarillas:\n",
    "                    self.letras_negras.add(letra)\n",
    "    \n",
    "    def filtrar_candidatas(self):\n",
    "        \"\"\"\n",
    "        Filtra palabras seg√∫n restricciones actuales\n",
    "        \"\"\"\n",
    "        candidatas = []\n",
    "        \n",
    "        for palabra in self.palabras:\n",
    "            valida = True\n",
    "            \n",
    "            # Verificar letras verdes (deben estar en su posici√≥n)\n",
    "            for pos, letra in self.letras_verdes.items():\n",
    "                if palabra[pos] != letra:\n",
    "                    valida = False\n",
    "                    break\n",
    "            \n",
    "            if not valida:\n",
    "                continue\n",
    "            \n",
    "            # Verificar letras amarillas (deben estar pero no en ciertas posiciones)\n",
    "            for letra in self.letras_amarillas:\n",
    "                if letra not in palabra:\n",
    "                    valida = False\n",
    "                    break\n",
    "                # Verificar que no est√© en posiciones descartadas\n",
    "                if letra in self.letras_amarillas_pos:\n",
    "                    for pos_no in self.letras_amarillas_pos[letra]:\n",
    "                        if palabra[pos_no] == letra:\n",
    "                            valida = False\n",
    "                            break\n",
    "            \n",
    "            if not valida:\n",
    "                continue\n",
    "            \n",
    "            # Verificar letras negras (no deben estar)\n",
    "            for letra in self.letras_negras:\n",
    "                if letra in palabra:\n",
    "                    valida = False\n",
    "                    break\n",
    "            \n",
    "            if valida:\n",
    "                candidatas.append(palabra)\n",
    "        \n",
    "        return candidatas\n",
    "    \n",
    "    def sugerir_palabra_probable(self, top_n=5):\n",
    "        \"\"\"\n",
    "        Sugiere las palabras m√°s probables de ser la respuesta\n",
    "        \"\"\"\n",
    "        candidatas = self.filtrar_candidatas()\n",
    "        \n",
    "        if not candidatas:\n",
    "            return []\n",
    "        \n",
    "        # Crear features y predecir\n",
    "        features = np.array([\n",
    "            crear_features_palabra(p, self.estadisticas, self.frecuencia_global)\n",
    "            for p in candidatas\n",
    "        ])\n",
    "        \n",
    "        scores = self.modelo.predict(features, verbose=0).flatten()\n",
    "        \n",
    "        # Ordenar por score\n",
    "        indices_ordenados = np.argsort(scores)[::-1]\n",
    "        \n",
    "        return [(candidatas[i], float(scores[i])) for i in indices_ordenados[:top_n]]\n",
    "    \n",
    "    def sugerir_palabra_exploradora(self, top_n=5):\n",
    "        \"\"\"\n",
    "        Sugiere palabras que maximicen la informaci√≥n (m√°s letras diferentes)\n",
    "        \"\"\"\n",
    "        candidatas = self.filtrar_candidatas()\n",
    "        \n",
    "        if not candidatas:\n",
    "            return []\n",
    "        \n",
    "        # Calcular score de exploraci√≥n\n",
    "        scores_exploracion = []\n",
    "        for palabra in candidatas:\n",
    "            # Contar letras √∫nicas no descubiertas\n",
    "            letras_conocidas = set(self.letras_verdes.values()) | self.letras_amarillas | self.letras_negras\n",
    "            letras_nuevas = set(palabra) - letras_conocidas\n",
    "            # Score: cantidad de letras nuevas * frecuencia promedio\n",
    "            score = len(letras_nuevas) * sum(self.frecuencia_global.get(l, 0) for l in letras_nuevas)\n",
    "            scores_exploracion.append(score)\n",
    "        \n",
    "        # Ordenar por score de exploraci√≥n\n",
    "        indices_ordenados = np.argsort(scores_exploracion)[::-1]\n",
    "        \n",
    "        return [(candidatas[i], float(scores_exploracion[i])) for i in indices_ordenados[:top_n]]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reinicia el asistente para una nueva partida\"\"\"\n",
    "        self.letras_verdes = {}\n",
    "        self.letras_amarillas = set()\n",
    "        self.letras_amarillas_pos = {}\n",
    "        self.letras_negras = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proporciona funciones para procesar entradas del usuario en formato PALABRA/COLORES y un modo interactivo que permite jugar m√∫ltiples partidas con el asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.822863Z",
     "iopub.status.busy": "2025-12-23T13:32:15.822552Z",
     "iopub.status.idle": "2025-12-23T13:32:15.848658Z",
     "shell.execute_reply": "2025-12-23T13:32:15.847285Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.822840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crear_interfaz(asistente):\n",
    "    # Estilos CSS\n",
    "    display(HTML(\"\"\"\n",
    "    <style>\n",
    "        .wordle-title {\n",
    "            text-align: center;\n",
    "            color: #2c3e50;\n",
    "            font-size: 32px;\n",
    "            font-weight: bold;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .wordle-subtitle {\n",
    "            text-align: center;\n",
    "            color: #7f8c8d;\n",
    "            font-size: 16px;\n",
    "            margin-bottom: 30px;\n",
    "        }\n",
    "        .resultado-box {\n",
    "            background: #E09116;\n",
    "            border-left: 4px solid #4CAF50;\n",
    "            padding: 15px;\n",
    "            margin: 10px 0;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        .candidatas-count {\n",
    "            font-size: 20px;\n",
    "        }\n",
    "        .palabra-sugerida {\n",
    "            background: #2c3e50;\n",
    "            padding: 10px;\n",
    "            margin: 5px 0;\n",
    "            border-radius: 5px;\n",
    "            font-family: monospace;\n",
    "            font-size: 16px;\n",
    "        }\n",
    "    </style>\n",
    "    <div class=\"wordle-title\">Asistente Wordle Espa√±ol</div>\n",
    "    <div class=\"wordle-subtitle\">Proyecto de Inteligencia Artificial - La Palabra del D√≠a</div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Widgets\n",
    "    palabra_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Ej: CANTO',\n",
    "        description='Palabra:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    colores_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Ej: VAANN',\n",
    "        description='Colores:',\n",
    "        style={'description_width': '80px'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    enviar_btn = widgets.Button(\n",
    "        description='Analizar',\n",
    "        button_style='primary',\n",
    "        #layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    \n",
    "    reset_btn = widgets.Button(\n",
    "        description='Nueva Partida',\n",
    "        button_style='warning',\n",
    "        #layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Instrucciones\n",
    "    instrucciones = widgets.HTML(\"\"\"\n",
    "    <div style='background: #2c3e50; padding: 15px; border-radius: 5px; margin: 10px 0;'>\n",
    "        <b>üìñ Instrucciones:</b><br>\n",
    "        1. Introduce la palabra que probaste en Wordle<br>\n",
    "        2. Introduce los colores: <b>V</b>=Verde, <b>A</b>=Amarillo, <b>N</b>=Negro<br>\n",
    "        3. Haz clic en \"Analizar\" para obtener sugerencias<br><br>\n",
    "        <i>Ejemplo: Si probaste CANTO y obtuviste üü©‚¨õüü®‚¨õ‚¨õ‚¨õ, escribe VAANN</i>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    def procesar_intento(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            palabra = palabra_input.value.strip().upper()\n",
    "            colores = colores_input.value.strip().upper()\n",
    "            \n",
    "            # Validaciones\n",
    "            if len(palabra) != 5:\n",
    "                print(\"‚ùå Error: La palabra debe tener 5 letras\")\n",
    "                return\n",
    "            if len(colores) != 5:\n",
    "                print(\"‚ùå Error: Debes proporcionar 5 colores\")\n",
    "                return\n",
    "            if not all(c in 'VAN' for c in colores):\n",
    "                print(\"‚ùå Error: Solo usa V, A o N para los colores\")\n",
    "                return\n",
    "            \n",
    "            # Actualizar y obtener sugerencias\n",
    "            asistente.actualizar_feedback(palabra, colores)\n",
    "            candidatas = asistente.filtrar_candidatas()\n",
    "            \n",
    "            display(HTML(f\"\"\"\n",
    "            <div class=\"resultado-box\">\n",
    "                <h3>Intento procesado: {palabra} ‚Üí {colores}</h3>\n",
    "                <p class=\"candidatas-count\">Candidatas restantes: {len(candidatas)}</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            \n",
    "            if len(candidatas) == 0:\n",
    "                print(\"‚ö†Ô∏è No quedan candidatas. Verifica los colores ingresados.\")\n",
    "                return\n",
    "            \n",
    "            # Top palabras probables\n",
    "            print(\"\\nüèÜ TOP 5 PALABRAS M√ÅS PROBABLES:\")\n",
    "            probables = asistente.sugerir_palabra_probable(top_n=5)\n",
    "            for i, (pal, score) in enumerate(probables, 1):\n",
    "                display(HTML(f'<div class=\"palabra-sugerida\">{i}. <b>{pal}</b> (confianza: {score:.4f})</div>'))\n",
    "            \n",
    "            # Palabras exploradoras\n",
    "            print(\"\\nüîç TOP 5 PALABRAS QUE APORTAN M√ÅS INFORMACI√ìN:\")\n",
    "            exploradoras = asistente.sugerir_palabra_exploradora(top_n=5)\n",
    "            for i, (pal, score) in enumerate(exploradoras, 1):\n",
    "                display(HTML(f'<div class=\"palabra-sugerida\">{i}. <b>{pal}</b> (info: {score:.1f})</div>'))\n",
    "            \n",
    "            # Estado actual\n",
    "            if asistente.letras_verdes or asistente.letras_amarillas or asistente.letras_negras:\n",
    "                print(\"\\nüìå ESTADO ACTUAL:\")\n",
    "                if asistente.letras_verdes:\n",
    "                    print(f\"   üü© Verdes: {asistente.letras_verdes}\")\n",
    "                if asistente.letras_amarillas:\n",
    "                    print(f\"   üü® Amarillas: {asistente.letras_amarillas}\")\n",
    "                if asistente.letras_negras:\n",
    "                    print(f\"   ‚¨õ Negras: {asistente.letras_negras}\")\n",
    "            \n",
    "            # Limpiar inputs\n",
    "            palabra_input.value = ''\n",
    "            colores_input.value = ''\n",
    "    \n",
    "    def resetear(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            asistente.reset()\n",
    "            palabra_input.value = ''\n",
    "            colores_input.value = ''\n",
    "            print(\"üîÑ Asistente reiniciado. ¬°Nueva partida iniciada!\")\n",
    "    \n",
    "    enviar_btn.on_click(procesar_intento)\n",
    "    reset_btn.on_click(resetear)\n",
    "    \n",
    "    # Layout\n",
    "    input_box = widgets.VBox(\n",
    "        [\n",
    "            widgets.HBox([palabra_input, colores_input]),\n",
    "            enviar_btn,\n",
    "            reset_btn\n",
    "        ],\n",
    "        layout=widgets.Layout(\n",
    "            width='90%',\n",
    "            gap='15px'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    contenedor = widgets.HBox(\n",
    "        [input_box],\n",
    "        layout=widgets.Layout(justify_content='center')\n",
    "    )\n",
    "\n",
    "    \n",
    "    display(instrucciones)\n",
    "    display(input_box)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecuci√≥n principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene la funci√≥n main() que orquesta todo el flujo del programa: descarga de palabras, entrenamiento del modelo, inicializaci√≥n del asistente y gesti√≥n del modo interactivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T13:32:15.849942Z",
     "iopub.status.busy": "2025-12-23T13:32:15.849677Z",
     "iopub.status.idle": "2025-12-23T13:32:36.146746Z",
     "shell.execute_reply": "2025-12-23T13:32:36.145727Z",
     "shell.execute_reply.started": "2025-12-23T13:32:15.849920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando asistente...\n",
      "Descargadas 636598 palabras de API\n",
      "Palabras v√°lidas para Wordle: 10836\n",
      " 10836 palabras cargadas\n",
      "\n",
      "2. Analizando frecuencias de letras...\n",
      " Estad√≠sticas calculadas\n",
      "   Letras m√°s comunes: [('A', 8814), ('E', 5378), ('O', 5337), ('S', 3844), ('R', 3666)]\n",
      "\n",
      "3. Generando datos de entrenamiento...\n",
      "\n",
      "4. Entrenando modelo de red neuronal...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m asistente, modelo, palabras, estadisticas, frecuencia_global\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Ejecutar\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Inicializar el asistente\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m asistente, modelo, palabras, estadisticas, frecuencia_global = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Crear interfaz interactiva\u001b[39;00m\n\u001b[32m     55\u001b[39m crear_interfaz(asistente)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 4. Entrenar modelo\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m4. Entrenando modelo de red neuronal...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m modelo = \u001b[43mcrear_modelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m split_idx = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m * \u001b[38;5;28mlen\u001b[39m(X))\n\u001b[32m     23\u001b[39m X_train, X_val = X[:split_idx], X[split_idx:]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcrear_modelo\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcrear_modelo\u001b[39m():\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Red neuronal para scoring de palabras\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     modelo = \u001b[43mkeras\u001b[49m.Sequential([\n\u001b[32m      6\u001b[39m         layers.Input(shape=(\u001b[32m33\u001b[39m,)),  \u001b[38;5;66;03m# 26 + 5 + 1 + 1\u001b[39;00m\n\u001b[32m      7\u001b[39m         layers.Dense(\u001b[32m128\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      8\u001b[39m         layers.Dropout(\u001b[32m0.3\u001b[39m),\n\u001b[32m      9\u001b[39m         layers.Dense(\u001b[32m64\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m         layers.Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m     11\u001b[39m         layers.Dense(\u001b[32m32\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     12\u001b[39m         layers.Dense(\u001b[32m1\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Score de 0 a 1\u001b[39;00m\n\u001b[32m     13\u001b[39m     ])\n\u001b[32m     15\u001b[39m     modelo.compile(\n\u001b[32m     16\u001b[39m         optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m         loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m         metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m modelo\n",
      "\u001b[31mNameError\u001b[39m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # 1. Descargar y preparar palabras\n",
    "    print(\"Inicializando asistente...\")\n",
    "    palabras_raw = descargar_palabras_api()\n",
    "    palabras = filtrar_palabras_wordle(palabras_raw)\n",
    "    print(f\" {len(palabras)} palabras cargadas\")\n",
    "    \n",
    "    # 2. Crear estad√≠sticas\n",
    "    print(\"\\n2. Analizando frecuencias de letras...\")\n",
    "    estadisticas, frecuencia_global = crear_estadisticas_letras(palabras)\n",
    "    print(\" Estad√≠sticas calculadas\")\n",
    "    print(f\"   Letras m√°s comunes: {frecuencia_global.most_common(5)}\")\n",
    "    \n",
    "    # 3. Preparar datos de entrenamiento\n",
    "    print(\"\\n3. Generando datos de entrenamiento...\")\n",
    "    X, y = generar_datos_entrenamiento(palabras, estadisticas, frecuencia_global)\n",
    "    \n",
    "    # 4. Entrenar modelo\n",
    "    print(\"\\n4. Entrenando modelo de red neuronal...\")\n",
    "    modelo = crear_modelo()\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    print(\"Entrenando modelo...\")\n",
    "    modelo.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "               epochs=20, batch_size=32, verbose=1)\n",
    "    print(\"Modelo entrenado\")\n",
    "    \n",
    "    # 5. Crear asistente\n",
    "    print(\"\\n5. Inicializando asistente...\")\n",
    "    asistente = WordleAssistant(palabras, modelo, estadisticas, frecuencia_global)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ASISTENTE LISTO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Guardar modelo y datos\n",
    "    print(\"\\n6. Guardando modelo y datos...\")\n",
    "    modelo.save('wordle_assistant_model.keras')\n",
    "    print(\"   Modelo guardado como 'wordle_assistant_model.keras'\")\n",
    "    \n",
    "    with open('palabras_wordle.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(palabras))\n",
    "    print(\"   Palabras guardadas en 'palabras_wordle.txt'\")\n",
    "    \n",
    "    return asistente, modelo, palabras, estadisticas, frecuencia_global\n",
    "\n",
    "# Ejecutar\n",
    "# Inicializar el asistente\n",
    "asistente, modelo, palabras, estadisticas, frecuencia_global = main()\n",
    "\n",
    "# Crear interfaz interactiva\n",
    "crear_interfaz(asistente)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
